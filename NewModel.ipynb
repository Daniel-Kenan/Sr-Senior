{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321ec97-2b21-4131-9deb-fb6362466107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ff9cb9-b5e4-4c26-863e-e2def97994e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "Improved     74966\n",
      "Unchanged    45095\n",
      "Worsened     29939\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset (replace with your actual file path)\n",
    "data = pd.read_csv('Final_healthcare_big_data.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_features = ['Daily_Patient_Inflow', 'Emergency_Response_Time_Minutes', 'Staff_Count', \n",
    "                      'Bed_Occupancy_Rate', 'Visit_Frequency', 'Wait_Time_Minutes', \n",
    "                      'Length_of_Stay', 'Previous_Visits', 'Resource_Utilization', 'Age']\n",
    "categorical_features = ['Treatment_Outcome', 'Equipment_Availability', 'Medicine_Stock_Level', \n",
    "                        'Comorbidities', 'Disease_Category']\n",
    "ordinal_features = ['Satisfaction_Rating']  # Treat as numerical/ordinal\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))  # Updated parameter\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())  # Scale ordinal data\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('ord', ordinal_transformer, ordinal_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Check for imbalanced target\n",
    "print(y.value_counts())  # Ensure 'Outcome' is balanced or apply balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621443b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f128dd3-f5c0-47ca-879c-31e6c0e5b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final_healthcare_big_data.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Encode the target variable (Outcome) to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Converts 'Improved', 'Unchanged', 'Worsened' to 0, 1, 2\n",
    "# Store the mapping for later (optional, for interpretation)\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Encoding Mapping:\", label_mapping)\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "numerical_features = ['Daily_Patient_Inflow', 'Emergency_Response_Time_Minutes', 'Staff_Count', \n",
    "                      'Bed_Occupancy_Rate', 'Visit_Frequency', 'Wait_Time_Minutes', \n",
    "                      'Length_of_Stay', 'Previous_Visits', 'Resource_Utilization', 'Age']\n",
    "categorical_features = ['Treatment_Outcome', 'Equipment_Availability', 'Medicine_Stock_Level', \n",
    "                        'Comorbidities', 'Disease_Category']\n",
    "ordinal_features = ['Satisfaction_Rating']  # Treat as numerical/ordinal\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))  # Updated parameter\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())  # Scale ordinal data\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('ord', ordinal_transformer, ordinal_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the features\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Handle imbalanced data with SMOTE (on encoded target)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_processed, y_encoded)\n",
    "\n",
    "# Split the balanced data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Model with class weights\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# XGBoost Model with class weights (use numerical labels)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, scale_pos_weight='balanced')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Decode predictions back to original labels for reporting\n",
    "rf_pred_decoded = label_encoder.inverse_transform(rf_pred)\n",
    "xgb_pred_decoded = label_encoder.inverse_transform(xgb_pred)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate both models\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test_decoded, rf_pred_decoded))\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test_decoded, xgb_pred_decoded))\n",
    "\n",
    "# Confusion Matrix for Random Forest (with decoded labels)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test_decoded, rf_pred_decoded)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Improved', 'Unchanged', 'Worsened'], \n",
    "            yticklabels=['Improved', 'Unchanged', 'Worsened'])\n",
    "plt.title('Confusion Matrix (Random Forest)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance (Random Forest)\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = (numerical_features + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)) + \n",
    "                 ordinal_features)\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "print(feature_importance_df.sort_values(by='Importance', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1feed-865d-4c7d-96f1-ca607cdd8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy={1: 74966, 2: 74966})  # Target \"Unchanged\" and \"Worsened\" to match \"Improved\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67ff87-6cf0-4b18-92b8-51cfab56de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "oversample = SMOTE(random_state=42)\n",
    "undersample = RandomUnderSampler(random_state=42)\n",
    "pipeline = ImbPipeline(steps=[('over', oversample), ('under', undersample)])\n",
    "X_balanced, y_balanced = pipeline.fit_resample(X_processed, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ca476-2b37-41c9-9348-347cf7f8e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
    "class_weight_dict = dict(zip(np.unique(y_encoded), class_weights))\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight_dict)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, scale_pos_weight=sum(y_encoded==0)/sum(y_encoded==2))  # Adjust for \"Worsened\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00870d-d12f-4b73-b8f6-945813a7af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42, class_weight='balanced'), param_grid_rf, cv=5, scoring='f1_weighted')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "print(\"Best RF Params:\", grid_search_rf.best_params_)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3]\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, scale_pos_weight='balanced'), param_grid_xgb, cv=5, scoring='f1_weighted')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "print(\"Best XGBoost Params:\", grid_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6051a3-ee79-46dc-838c-c4a00e4b3c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd50f0-13c1-4c18-8f80-453929836534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
